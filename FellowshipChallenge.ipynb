{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/18/21: Got to the point where I'm going to train a PET model,  should take a few hours but it's getting late so I'm just going to let that run and upload the results tomorrow. If you're reading this now feel free to look through but expect more soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test= fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure that the data lengths match up with what's on http://qwone.com/~jason/20Newsgroups/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7532"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_test['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11314 + 7532"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "Next going to do some basic EDA on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\n",
      "Subject: Re: Rewording the Second Amendment (ideas)\n",
      "Organization: VTT\n",
      "Lines: 58\n",
      "\n",
      "In article <1r1eu1$4t@transfer.stratus.com> cdt@sw.stratus.com (C. D. Tavares) writes:\n",
      ">In article <1993Apr20.083057.16899@ousrvr.oulu.fi>, dfo@vttoulu.tko.vtt.fi (Foxvog Douglas) writes:\n",
      ">> In article <1qv87v$4j3@transfer.stratus.com> cdt@sw.stratus.com (C. D. Tavares) writes:\n",
      ">> >In article <C5n3GI.F8F@ulowell.ulowell.edu>, jrutledg@cs.ulowell.edu (John Lawrence Rutledge) writes:\n",
      ">\n",
      ">> >> The massive destructive power of many modern weapons, makes the\n",
      ">> >> cost of an accidental or crimial usage of these weapons to great.\n",
      ">> >> The weapons of mass destruction need to be in the control of\n",
      ">> >> the government only.  Individual access would result in the\n",
      ">> >> needless deaths of millions.  This makes the right of the people\n",
      ">> >> to keep and bear many modern weapons non-existant.\n",
      "\n",
      ">> >Thanks for stating where you're coming from.  Needless to say, I\n",
      ">> >disagree on every count.\n",
      "\n",
      ">> You believe that individuals should have the right to own weapons of\n",
      ">> mass destruction?  I find it hard to believe that you would support a \n",
      ">> neighbor's right to keep nuclear weapons, biological weapons, and nerve\n",
      ">> gas on his/her property.  \n",
      "\n",
      ">> If we cannot even agree on keeping weapons of mass destruction out of\n",
      ">> the hands of individuals, can there be any hope for us?\n",
      "\n",
      ">I don't sign any blank checks.\n",
      "\n",
      "Of course.  The term must be rigidly defined in any bill.\n",
      "\n",
      ">When Doug Foxvog says \"weapons of mass destruction,\" he means CBW and\n",
      ">nukes.  When Sarah Brady says \"weapons of mass destruction\" she means\n",
      ">Street Sweeper shotguns and semi-automatic SKS rifles.  \n",
      "\n",
      "I doubt she uses this term for that.  You are using a quote allegedly\n",
      "from her, can you back it up?\n",
      "\n",
      ">When John\n",
      ">Lawrence Rutledge says \"weapons of mass destruction,\" and then immediately\n",
      ">follows it with:\n",
      "\n",
      ">>> The US has thousands of people killed each year by handguns,\n",
      ">>> this number can easily be reduced by putting reasonable restrictions\n",
      ">>> on them.\n",
      "\n",
      ">...what does Rutledge mean by the term?\n",
      "\n",
      "I read the article as presenting first an argument about weapons of mass\n",
      "destruction (as commonly understood) and then switching to other topics.\n",
      "The first point evidently was to show that not all weapons should be\n",
      "allowed, and then the later analysis was, given this understanding, to\n",
      "consider another class.\n",
      "\n",
      ">cdt@rocket.sw.stratus.com   --If you believe that I speak for my company,\n",
      ">OR cdt@vos.stratus.com        write today for my special Investors' Packet...\n",
      "\n",
      "\n",
      "\n",
      "-- \n",
      "doug foxvog\n",
      "douglas.foxvog@vtt.fi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train['data'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well this looks useful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out to reduce notebook length, pasted part of interest in markdown\n",
    "# print(newsgroups_train['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of interest in DESCR:\n",
    "## \"\n",
    ">### Filtering text for more realistic training\n",
    ">----------------------------------------------\n",
    ">\n",
    ">It is easy for a classifier to overfit on particular things that appear in the\n",
    ">20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\n",
    ">high F-scores, but their results would not generalize to other documents that\n",
    ">aren't from this window of time.\n",
    ">\n",
    ">For example, let's look at the results of a multinomial Naive Bayes classifier,\n",
    ">which is fast to train and achieves a decent F-score::\n",
    ">\n",
    "  >>> from sklearn.naive_bayes import MultinomialNB\n",
    "  >>> from sklearn import metrics\n",
    "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
    " > ...                                      categories=categories)\n",
    "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "  >>> clf = MultinomialNB(alpha=.01)\n",
    "  >>> clf.fit(vectors, newsgroups_train.target)\n",
    " > MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
    ">\n",
    "  >>> pred = clf.predict(vectors_test)\n",
    "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
    "  >0.88213...\n",
    ">\n",
    ">(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\n",
    ">the training and test data, instead of segmenting by time, and in that case\n",
    ">multinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\n",
    ">yet of what's going on inside this classifier?)\n",
    ">\n",
    ">Let's take a look at what the most informative features are:\n",
    ">\n",
    "  >>> import numpy as np\n",
    "  >>> def show_top10(classifier, vectorizer, categories):\n",
    "  >...     feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "  >...     for i, category in enumerate(categories):\n",
    "  >...         top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "  >...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "  >...\n",
    "  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
    "  >alt.atheism: edu it and in you that is of to the\n",
    "  >comp.graphics: edu in graphics it is for and of to the\n",
    "  >sci.space: edu it that is in and space to of the\n",
    "  >talk.religion.misc: not it you in is that and to of the\n",
    ">\n",
    ">\n",
    ">You can now see many things that these features have overfit to:\n",
    ">\n",
    ">- Almost every group is distinguished by whether headers such as\n",
    ">  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\n",
    ">- Another significant feature involves whether the sender is affiliated with\n",
    ">  a university, as indicated either by their headers or their signature.\n",
    ">- The word \"article\" is a significant feature, based on how often people quote\n",
    ">  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\n",
    ">  wrote:\"\n",
    ">- Other features match the names and e-mail addresses of particular people who\n",
    ">  were posting at the time.\n",
    ">\n",
    ">With such an abundance of clues that distinguish newsgroups, the classifiers\n",
    ">barely have to identify topics from text at all, and they all perform at the\n",
    ">same high level.\n",
    ">\n",
    ">For this reason, the functions that load 20 Newsgroups data provide a\n",
    ">parameter called **remove**, telling it what kinds of information to strip out\n",
    ">of each file. **remove** should be a tuple containing any subset of\n",
    ">``('headers', 'footers', 'quotes')``, telling it to remove headers, signature\n",
    ">blocks, and quotation blocks respectively.\n",
    ">\n",
    " > >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "  >...                                      remove=('headers', 'footers', 'quotes'),\n",
    "  >...                                      categories=categories)\n",
    "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "  >>> pred = clf.predict(vectors_test)\n",
    "  >>> metrics.f1_score(pred, newsgroups_test.target, average='macro')\n",
    "  >0.77310...\n",
    ">\n",
    ">This classifier lost over a lot of its F-score, just because we removed\n",
    ">metadata that has little to do with topic classification.\n",
    ">It loses even more if we also strip this metadata from the training data:\n",
    ">\n",
    " > >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "  >...                                       remove=('headers', 'footers', 'quotes'),\n",
    "  >...                                       categories=categories)\n",
    " > >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "  >>>> clf = MultinomialNB(alpha=.01)\n",
    "  >>>> clf.fit(vectors, newsgroups_train.target)\n",
    "  >MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
    ">\n",
    "  >>>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "  >>>> pred = clf.predict(vectors_test)\n",
    "  >>>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
    "  >0.76995...\n",
    ">\n",
    ">Some other classifiers cope better with this harder version of the task. Try\n",
    ">running :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\n",
    ">the ``--filter`` option to compare the results.  \n",
    "## \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful information from the value of `newsgroups_train['DESCR']`.\n",
    "\n",
    "Although, I'm a little confused by the output of their \"show_top_10\" function. They say \"You can now see many things that these features have overfit to:\" but then what they list doesn't seem to match up with their example output, so while I believe what they're talking about is likely true I'm going to re-run their code just to have a better understanding of what they're talking about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average vector nnz: 157.9958458546933\n",
      "TFIDF Matrix Density: 0.001214353154362896\n",
      "F1 Score: 0.8290659644474043\n"
     ]
    }
   ],
   "source": [
    "# Note that none of this is my code, just rerunning what they did to see what they're seeing:\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "\n",
    "print('Average vector nnz: {}'.format(str(vectors.nnz / vectors.shape[0])))\n",
    "print('TFIDF Matrix Density: {}'.format(str(vectors.nnz / (vectors.shape[0] * vectors.shape[1]))))\n",
    "\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "clf = MultinomialNB(alpha=0.01)\n",
    "clf.fit(vectors, newsgroups_train.target)\n",
    "\n",
    "pred = clf.predict(vectors_test)\n",
    "f1_score = metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
    "print('F1 Score: {}'.format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got a different F1 score, I presume that's because I didn't remove any categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: keith it and you in that is to of the\n",
      "comp.graphics: edu in for it is and graphics of to the\n",
      "comp.os.ms-windows.misc: file for of and edu is it to the windows\n",
      "comp.sys.ibm.pc.hardware: card ide is of it drive and scsi to the\n",
      "comp.sys.mac.hardware: in it is and of edu apple mac to the\n",
      "comp.windows.x: it mit in motif and is of window to the\n",
      "misc.forsale: shipping offer of 00 to and edu the for sale\n",
      "rec.autos: that is you it in of and to car the\n",
      "rec.motorcycles: dod you it com in of and bike to the\n",
      "rec.sport.baseball: that is baseball and of in to he edu the\n",
      "rec.sport.hockey: ca game he team and hockey of in to the\n",
      "sci.crypt: chip that encryption is and clipper key of to the\n",
      "sci.electronics: for edu you it in is and of to the\n",
      "sci.med: edu pitt that it in and is to of the\n",
      "sci.space: it that is nasa in and to of space the\n",
      "soc.religion.christian: we it in and is god that to of the\n",
      "talk.politics.guns: it is you that gun and in of to the\n",
      "talk.politics.mideast: is you israeli that israel in and to of the\n",
      "talk.politics.misc: edu it is you and in that of to the\n",
      "talk.religion.misc: sandvik god you in is that and to of the\n"
     ]
    }
   ],
   "source": [
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(clf, vectorizer, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay... so I'm admittedly a bit confused because these results look the same as they had before xD\n",
    "\n",
    "To whoever is reading this, this is the part in ``DESCR`` that is throwing me off:  \n",
    "\n",
    ">\"You can now see many things that these features have overfit to:\n",
    "\n",
    ">- Almost every group is distinguished by whether headers such as\n",
    "  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\n",
    ">- Another significant feature involves whether the sender is affiliated with\n",
    "  a university, as indicated either by their headers or their signature.\n",
    ">- The word \"article\" is a significant feature, based on how often people quote\n",
    "  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\n",
    "  wrote:\"\n",
    ">- Other features match the names and e-mail addresses of particular people who\n",
    "  were posting at the time.\"\n",
    "\n",
    "Okay upon re-reading, it's the way that they're switching the contexts at which they're using the word \"feature\" here that's throwing me off. In some cases they're directly referring to tokens, in others they're talking more abstractly. \n",
    "\n",
    "Here's what I'm getting from this output:\n",
    "\n",
    "- I do see some problems with overfitting, for example in `alt.atheism` one of the most \"informative\" tokens according to NB is \"keith\" which lines up with what they're saying about names and email addresses. \n",
    "\n",
    "- I see a lot of stop words as the top features which makes sense because it is NB afterall and we didn't prune the stop words. It seems that these \"informative\" tokens are just the most likely token given the class, which has an obvious frequency bias. (Just looked up what `MultinomialNB.coef_` is in sklearn docs) `coef_` is equivalent to another attr `feature_log_prob_`. So these tokens are in fact just $P(token_i|class_k)$. \n",
    "\n",
    "I've decided that I don't really like their approach to analyzing what NB is finding. They're describing these tokens as the \"most informative features\" but is $P(token_i|class_k)$ really a good measure of how \"informative\" a token is for the class? I don't personally think so, so I'm going to use Bayes Theorem to calculate `P(class|token)` to get a better idea of what NB is finding in absent of frequency bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem!\n",
    "So in this section I'm going to calculate $P(class_k|token_i)$ for all classes and tokens, then make another ``show_top10`` function that prints token importances according to that to see what comes back out.\n",
    "\n",
    "First going to verify that sklearn didn't do anything funky to the probabilities, should be able to just np.exp it and it should add up to ~20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.00000000000001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(clf.feature_log_prob_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems good me! Let's check the class probabilities now, should add up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(clf.class_log_prior_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!\n",
    "\n",
    "As a reminder, we're trying to calculate this:  \n",
    "\n",
    "$P(class_k|token_i) = \\frac{P(token_i|class_k) P(class_k)}{P(token_i)}$\n",
    "\n",
    "where $P(token_i) = \\sum_{k}^{n}{P(token_i|class_k) P(class_k)}$\n",
    "\n",
    "Here's how we calculate the individual elements:  \n",
    "``np.exp(clf.coef_)`` = ``np.exp(clf.feature_log_prob_)`` = $P(token_i|class_k)$  \n",
    "``np.exp(clf.class_log_prior_)`` = $P(class_k)$  \n",
    "``np.sum(np.multiply(token_given_class_probs.T, class_probs).T, axis=0)`` =  $\\sum_{k}^{n}{P(token_i|class_k) P(class_k)} = P(token_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all together now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_given_tokens_probs(classifier):\n",
    "    token_given_class_probs = np.exp(classifier.feature_log_prob_)\n",
    "    class_probs = np.exp(classifier.class_log_prior_)\n",
    "    token_probs = np.sum(np.multiply(token_given_class_probs.T, class_probs).T, axis=0)\n",
    "    return np.multiply(np.multiply(token_given_class_probs.T, class_probs).T, np.reciprocal(token_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_given_token_probs = get_class_given_tokens_probs(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we did everything right and verify that class probabilities given any token adds up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(class_given_token_probs[:, 1001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good to me! Now for the new ``show_top10`` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: schneider darice benedikt snm6394 buphy mozumder rushdie beauchaine bobbe jaeger\n",
      "comp.graphics: mpeg rayshade bezier tdawson radiosity 3do polygon tiff pov cview\n",
      "comp.os.ms-windows.misc: ndis chicogo 2a42dubinski mathcad winqvt win3 nthu ashok ini w4wg\n",
      "comp.sys.ibm.pc.hardware: penev gerhards husak tosspot harddisk t560i f550iw balog ab245 latonia\n",
      "comp.sys.mac.hardware: iivx lc hades pds adb bmug powerbook iisi c650 lciii\n",
      "comp.windows.x: mydisplay xputimage whaley imake xterm xdm x11r5 enterpoop widget xpert\n",
      "misc.forsale: obo typewriter damico hiram snes 02106 koutd rupin radley kou\n",
      "rec.autos: wrat opel mr2 wharfie awd sho automotive qazi boyle callison\n",
      "rec.motorcycles: cjackson bike winona countersteering svoboda egreen moa bikes infante ranck\n",
      "rec.sport.baseball: rickert clemens mets dodgers pitcher baerga rbi phillies alomar pitching\n",
      "rec.sport.hockey: playoff devils ists hockey islanders hawks bruins lemieux leafs nhl\n",
      "sci.crypt: wiretap toal rsa intercon amanda bontchev encryption gtoal crypto escrow\n",
      "sci.electronics: fegmania relays skybridge vanderby cmkrnl transformer belton vanderbyl grissom adcom\n",
      "sci.med: spdcc migraine lyme zisfein candida chastity dsl n3jxp dyer geb\n",
      "sci.space: prb dietz centaur nicho orbit ssto egalon sysmgr spacecraft nsmca\n",
      "soc.religion.christian: rolfe mmalt gvg47 liturgy mussack kulikauskas jayne petch clh athos\n",
      "talk.politics.guns: glock ranch firearms handgun thomasp crary dividian kratz firearm feustel\n",
      "talk.politics.mideast: hernlem arab cpr arabs israeli argic armenians serdar armenia armenian\n",
      "talk.politics.misc: hendricks ronzone promiscuous ipser kinsey stephanopoulos drieux steveh kaldis cramer\n",
      "talk.religion.misc: meritt pmy yadlowsky oto amorc thyagi psyrobtw royalroads ch981 rosicrucian\n"
     ]
    }
   ],
   "source": [
    "def show_top10(classifier, vectorizer, categories): \n",
    "    class_given_token_probs = get_class_given_tokens_probs(classifier)\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(class_given_token_probs[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(clf, vectorizer, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly still some noise in there with mispellings and such, could probably reduce most of that by requiring a certain minimum frequency, let's do that real quick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: caltech cco morality keith islamic islam atheists wpd atheism livesey\n",
      "comp.graphics: package vga 256 library format gif image images graphics 3d\n",
      "comp.os.ms-windows.misc: dos ms microsoft driver drivers diamond font nt windows ax\n",
      "comp.sys.ibm.pc.hardware: port floppy gateway motherboard 486 scsi bus controller isa ide\n",
      "comp.sys.mac.hardware: mhz internal meg se upgrade dartmouth simms apple mac quadra\n",
      "comp.windows.x: event mit tu application server window motif xterm x11r5 widget\n",
      "misc.forsale: sell excellent includes 00 brand asking condition offer shipping sale\n",
      "rec.autos: lehigh honda auto saturn ford oil engine dealer car cars\n",
      "rec.motorcycles: nec honda bmw dog ride riding dod motorcycle bike bikes\n",
      "rec.sport.baseball: season hall stats fans hit players runs ball baseball braves\n",
      "rec.sport.hockey: montreal gld gerald detroit wings rangers espn hockey leafs nhl\n",
      "sci.crypt: secure des pgp privacy nsa clipper encryption gtoal crypto escrow\n",
      "sci.electronics: electrical nuclear ee input output signal ground audio electronics radar\n",
      "sci.med: pain medicine medical pitt gordon doctor disease banks msg geb\n",
      "sci.space: jpl dseg spencer space henry zoo moon alaska launch orbit\n",
      "soc.religion.christian: rutgers bible jesus faith christianity heaven christ christians church sin\n",
      "talk.politics.guns: arms stratus sw fbi weapons waco gun batf guns firearms\n",
      "talk.politics.mideast: turkey israel turkish arab israeli argic armenians serdar armenia armenian\n",
      "talk.politics.misc: health president isc trial clinton drugs tax gay optilink cramer\n",
      "talk.religion.misc: values context christian jesus objective morality koresh kent newton sandvik\n"
     ]
    }
   ],
   "source": [
    "def show_top10(classifier, vectorizer, categories): \n",
    "    class_given_token_probs = get_class_given_tokens_probs(classifier)\n",
    "    # Get approximate token count from class (pretty sure they're doing some sort of smoothing or something as these numbers aren't whole)\n",
    "    token_frequencies = np.sum(clf.feature_count_, axis=0)\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        argsorted = np.argsort(class_given_token_probs[i])\n",
    "        \n",
    "        # Use np.in1d on arrays of indices to check if there's overlap with array of indices that have a minimum of 10 occurrences\n",
    "        top10 = argsorted[np.in1d(argsorted, np.argwhere(token_frequencies > 10).flatten())][-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(clf, vectorizer, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks a lot better! I think it does a much better job at capturing which kinds of tokens really define the topic. We probably could have arrived at this set via TF-IDF as well but this is just as good. We can still see some of the issues though, with certain names of users really defining a particular topic. \"keith\" still seems to be a pretty noticable problem for NB in the atheism topic for example.\n",
    "\n",
    "As an example of a topic that this looks really good to me is the ``talk.politics.mideast``, I imagine that even possibly on a more modern text set that this model might still perform OK at identifying that topic. ``talk.politics.mist`` seems pretty out of date by comparison, but I guess the name Clinton even today probably still comes up quite a bit. I am curious about the \"Cramer\" and \"Optilink\" keywords though as I'm unsure what that's related to, so I'm going to print out some examples that contain those keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optilink_docs = [x for x in newsgroups_train['data'] if 'optilink' in x.lower()]\n",
    "cramer_docs = [x for x in newsgroups_train['data'] if 'cramer' in x.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: cramer@optilink.COM (Clayton Cramer)\n",
      "Subject: Re: New Study Out On Gay Percentage\n",
      "Organization: Optilink Corporation, Petaluma, CA\n",
      "Lines: 19\n",
      "\n",
      "In article <C5L0v1.JCv@news.cso.uiuc.edu>, dans@uxa.cso.uiuc.edu (Dan S.) writes:\n",
      "> Don't forget about the culture.  Sadly, we don't (as a society) look upon\n",
      "> homosexuality as normal (and as we are all too well aware, there are alot\n",
      "> of people who condemn it).  As a result, the gay population is not encouraged\n",
      "> to develop \"non-promiscuous\" relationships.  In fact there are many roadblocks\n",
      "> put in the way of such committed relationships.  It is as if the heterosexual\n",
      "\n",
      "Such as?  Not being able to get married isn't a roadblock to a permanent\n",
      "relationship.  Lack of a marriage certificate doesn't force a couple\n",
      "to break up.  This is an excuse used by homosexuals because the \n",
      "alternative is to ask why they are so much more promiscuous than \n",
      "straights.\n",
      "\n",
      "> Dan\n",
      "\n",
      "\n",
      "-- \n",
      "Clayton E. Cramer {uunet,pyramid}!optilink!cramer  My opinions, all mine!\n",
      "Relations between people to be by mutual consent, or not at all.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(optilink_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: cramer@optilink.COM (Clayton Cramer)\n",
      "Subject: Re: New Study Out On Gay Percentage\n",
      "Organization: Optilink Corporation, Petaluma, CA\n",
      "Lines: 31\n",
      "\n",
      "In article <1993Apr16.164638.27218@galileo.cc.rochester.edu>, as010b@uhura.cc.rochester.edu (Tree of Schnopia) writes:\n",
      "> In <15378@optilink.COM> cramer@optilink.COM (Clayton Cramer) writes:\n",
      "# #The article also contains numbers on the number of sexual partners.\n",
      "# #The median number of sexual partners for all men 20-39 was 7.3.\n",
      "# #Compared to the table I have already posted from Masters, Johnson,\n",
      "# #and Kolodny showing male homosexual partners, it is apparent that\n",
      "# #homosexual men are dramatically more promiscuous than the general\n",
      "# #male population.  It's a shame that we don't have a breakdown for\n",
      "# #straight men vs. gay/bi men -- that would show even more dramatically\n",
      "# #how much more promiscuous gay/bi men are.\n",
      "# \n",
      "# Possibly because gay/bi men are less likely to get married?\n",
      "\n",
      "Marriage isn't a requirement for a couple staying together.\n",
      "\n",
      "# What was the purpose of this post?  If it was to show a mindless obsession\n",
      "# with statistics, an incredibly flawed system of reasoning, and a repellent\n",
      "# hatemonger agenda, then the purpose was accomplished with panache.\n",
      "# \n",
      "# (a) Get a clue.  (b) Get a life.  (c) Get out of my face.  I'm not in yours.\n",
      "# \n",
      "# ----bi    Andrew D. Simchik\t\t\t\t\tSCHNOPIA!\n",
      "\n",
      "Yes you are.  When you and the rest of the homosexual community\n",
      "pass laws to impose your moral codes on me, by requiring me to\n",
      "hire, rent to, or otherwise associate with a homosexual against\n",
      "my will, yes, you are in my face.  Until homosexuals stop trying\n",
      "to impose their morals on me, I will be in your face about this.\n",
      "-- \n",
      "Clayton E. Cramer {uunet,pyramid}!optilink!cramer  My opinions, all mine!\n",
      "Relations between people to be by mutual consent, or not at all.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cramer_docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahh both are just from an email address of a man who has hopefully has updated \"His opinions, all his!\" since writing these posts. As a side note, I think it's this kind of stuff that makes it clear why we have to be careful with how we deploy models that train on massive text datasets scraped from around the web.\n",
    "\n",
    "I digress, the model is still clearly overfitting to the names/email addresses of frequent posters. \n",
    "\n",
    "If there were far more categories to classify here, I imagine that the performance would drop quite drastically, and not because a model trained on this set wouldn't necessarily be generalizing, but because of the nature of the overlap of topics might make it difficult to get things right. I imagine to achieve really high accuracy here (>=95%), without using data like the posters and such, I would have to feature engineer to make things unnaturally fit the decided classifications. For example, this guy Cramer is talking about gay marriage, I imagine that might have some overlap over in the categories about religion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA/Modeling with Masked Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could continue down the path of NB or some other simple model by removing stop words, removing sections that leak information that is bad for overfitting and such, and likely arrive somewhere with reasonable performance. \n",
    "\n",
    "But I've done these kinds of tasks quite a bit, but usually I don't have a fully labeled set. Thus I've gotten pretty good at exploring text data using MLMs in what I think is a cool novel approach to NLP tasks. \n",
    "\n",
    "Also, given how old this dataset if I'd be sad if we don't match, or at the very least come very close to SOTA, and when chasing SOTA you generally have to use a neural net, so that's what we're going to do here.\n",
    "\n",
    "Just checked [paperswithcode](https://paperswithcode.com/sota/text-classification-on-20news), and it says that SOTA is 88.6% accuracy, so that's the goal!\n",
    "\n",
    "Anyways, there was a really cool paper circulating around mid-last year that I've spent some time implementing for work/side projects.\n",
    "\n",
    "Yall may have heard of it, the paper is called [\"Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference\"](https://arxiv.org/pdf/2001.07676.pdf) but I refer to it just as \"PET\".\n",
    "\n",
    "\n",
    "\"PET\" stands for \"Pattern Exploit Training\" and it includes ideas from both of the suggested papers for this challenge.\n",
    "I also happen to have infrastructure already deployed to train/deploy these models so I'm going go ahead and save some time by using that xD\n",
    "\n",
    "## Brief overview of PET:\n",
    "\n",
    "#### Patterns and Verbalizers\n",
    "The \"**Pattern**\" in PET refers to using a cloze statement as a way of simplifying a NLP task for a masked langugage model (MLM) such as BERT, RoBERTa, GPT-2/3, etc. \n",
    "\n",
    "If you're not familiar with the term \"cloze statement\", you're probably familiar with the concept. You may remember them from elementary school, basically a cloze statement looks something like this:\n",
    "\n",
    "\"**Somebody once told me the world is gonna roll me, I ain't the sharpest _ _ _ in the shed ...** \"\n",
    "\n",
    "And if you were living anytime after the year 1999 you would likely instantaneously fill in the blank in your mind with the word \"**tool**\". \n",
    "\n",
    "If you think back to school you may recall that a lot of these fill-in-the-blank statements were often preceded by passages of text that you had to use to correctly fill in the right answer. We're basically treating our MLM like you would a toddler and doing the same thing.\n",
    "\n",
    "So we augment all of our data with the cloze statement, and ask the MLM to fill in it's most likely answer. But we often make it even easier for the model by actually providing it with a set of words to choose from, and mapping those words to classes that we can use to calculate error to help the model learn to pick the best fit. We call these Label -> Token mappings \"**Verbalizers**\". \n",
    "\n",
    "The paper makes a point of calling the pairs of Patterns and Verbalizers \"Pattern Verbalizer Pairs\" (PVPs) but in my experience using PET, you often can use multiple verbalizers or a single verbalizer for many or few patterns. You also don't necessarily even need a verbalizer for certain tasks such as text generation, but that's something I haven't personally experimented with as much.\n",
    "\n",
    "I love this idea because it allows the modeler to be really creative in how they construct the patterns and verbalizers, it's a really natural form of feature engineering that I haven't really seen anywhere else before.\n",
    "\n",
    "#### Yelp Example:\n",
    "I found the paper's example of the Yelp dataset to be helpful in understanding what's going on:  \n",
    "\n",
    "Yelp Review: \"Best pizza ever!\"   \n",
    "Pattern (cloze statement): \"It was _ _ _ .\"  \n",
    "Verbalizers: {\"5 stars\": \"Great\", \"4 stars\": \"Good\", \"3 stars\": \"Okay\", \"2 stars\": \"Bad\", \"1 stars\": \"Terrible\"}\n",
    "\n",
    "So the model recieves \"Best Pizza ever! It was _ _ _ .\" as input and is asked to fill in the best answer out of:\n",
    "- Great\n",
    "- Good\n",
    "- Okay\n",
    "- Bad\n",
    "- Terrible\n",
    "\n",
    "If the real label here was \"5 stars\" and the model output the token \"Good\" then we would tell the model that the correct answer was in fact \"Great\".\n",
    "\n",
    "#### Using multiple patterns/models \n",
    "\n",
    "Here is where the idea starts to go up a level. \n",
    "\n",
    "Paper says, let's not just use one pattern, but let's use multiple to give the model multiple perspectives on the same task. So we train a model per PVP, then use those models to label a larger unlabeled dataset **D**.  \n",
    "\n",
    "We then train a final classifier on **D** without augementing the data with any patterns, but only by using the aggregate of labels from all the previous models.   \n",
    "\n",
    "If you're familiar with [Snorkel](https://www.snorkel.org/get-started/), it reminds me a lot of some of the ideas from that except instead of using human constructed label functions you're using human supervised machine-learned label functions. Also vanilla PET's label-weighting scheme isn't as well thought out as Snorkel's.\n",
    "\n",
    "\n",
    "This idea allows us to label a much larger dataset without needing that many labels, even with just 10-20 examples per class I typically see pretty good performance.\n",
    "\n",
    "#### PET-ception (**iPET**)\n",
    "\n",
    "The \"i\" in iPET stands for \"iterative\". So naturally what we do here is we repeat PET in stages. \n",
    "Stage 1 is basically exactly as I just described in normal PET, but instead of labeling just 1 dataset, we label N datasets, 1 for each model. But we only take the top K labels that the model is most confident about, and use that to train the next generation of models. We exclude each model's own labels from being included in the weighting of the labels for it's next dataset to prevent overfitting.  \n",
    "\n",
    "We can repeat this process as much as we want, but the paper suggests that you pick some factor to increase the number of top k highest confidence labels to include in the next generation until you've labeled the whole dataset. Once you've labeled the whole dataset you train a final classifier as you do in the original PET.\n",
    "\n",
    "\n",
    "This actually allows us to start with zero labels if we want to! Not that getting 10-20 hand labeled datapoints for each class is a problem, and it does generally perform quite a bit better even with just a few labels but still cool none-the-less. \n",
    "\n",
    "#### EDA with PET-esque patterns & MLMs\n",
    "This is where I divert a bit from the paper as I've used PET quite a bit in practice and have developed some process around it.\n",
    "\n",
    "What I'm going to do is take the ``transformers`` library, download and intitate a fresh RoBERTa large model, come up with some cloze statements to augment the data, and see how answers vary with different classes of documents. Normally I have to first find good examples to hand-label but we get to skip that here because we already have labels.  \n",
    "\n",
    "So what we're going to be getting out of this is hopefully some different interesting annotations from RoBERTa that we can analyze to better understand the dataset, and if we believe the annotations are good, come up with some verbalizers that we can use to train a PET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm = pipeline(task='fill-mask', device=0, model='roberta-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how to use transformers mlm pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Hello everyone!',\n",
       "  'score': 0.3271038234233856,\n",
       "  'token': 961,\n",
       "  'token_str': ' everyone'},\n",
       " {'sequence': 'Hello there!',\n",
       "  'score': 0.12918904423713684,\n",
       "  'token': 89,\n",
       "  'token_str': ' there'},\n",
       " {'sequence': 'Hello Everyone!',\n",
       "  'score': 0.12879636883735657,\n",
       "  'token': 7632,\n",
       "  'token_str': ' Everyone'},\n",
       " {'sequence': 'Hello again!',\n",
       "  'score': 0.07122993469238281,\n",
       "  'token': 456,\n",
       "  'token_str': ' again'},\n",
       " {'sequence': 'Hello all!',\n",
       "  'score': 0.03463467210531235,\n",
       "  'token': 70,\n",
       "  'token_str': ' all'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm('Hello <mask>!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``<mask>`` token is specific to RoBERTa I believe. What token you have to use varies with the pretrained MLM that you choose but it all boils down to \"Fill this blank in\". As of right now, transformers only let's you use one mask token at a time, so all outputs are limited to single tokens.\n",
    "\n",
    "You can also limit the tokens that the mlm has access to with the ``targets`` keyword (similar to what PET does).\n",
    "\n",
    "(Note: For whatever reason you need to precede your target tokens with a space, pretty sure this requirement varies with the kind of pretrained model that you choose.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Hello there!',\n",
       "  'score': 0.12918904423713684,\n",
       "  'token': 89,\n",
       "  'token_str': ' there'},\n",
       " {'sequence': 'Hello world!',\n",
       "  'score': 0.011702324263751507,\n",
       "  'token': 232,\n",
       "  'token_str': ' world'},\n",
       " {'sequence': 'Hello Dave!',\n",
       "  'score': 6.752090121153742e-05,\n",
       "  'token': 4475,\n",
       "  'token_str': ' Dave'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm('Hello <mask>!', targets=[' world', ' Dave', ' there'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the token probabilities don't change with what targets you choose to look for, \"there\" has .129 for this pattern regardless of which targets you choose to look for.'\n",
    "\n",
    "The outputs you get are really sensitive to small changes in the pattern, for example if I change the exclamation point to a period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Hello there.',\n",
       "  'score': 0.1809077262878418,\n",
       "  'token': 89,\n",
       "  'token_str': ' there'},\n",
       " {'sequence': 'Hello everyone.',\n",
       "  'score': 0.16616928577423096,\n",
       "  'token': 961,\n",
       "  'token_str': ' everyone'},\n",
       " {'sequence': 'Hello again.',\n",
       "  'score': 0.1222020760178566,\n",
       "  'token': 456,\n",
       "  'token_str': ' again'},\n",
       " {'sequence': 'Hello Mr.',\n",
       "  'score': 0.05068979039788246,\n",
       "  'token': 427,\n",
       "  'token_str': ' Mr'},\n",
       " {'sequence': 'Hello Dr.',\n",
       "  'score': 0.03387556970119476,\n",
       "  'token': 925,\n",
       "  'token_str': ' Dr'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm('Hello <mask>.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sensitivity is pretty realistic to how people actually write text in my opinion. A period after two words has a very different feel than one with an exclamation point. \n",
    "\n",
    "Also good to note is just how important including punctuation is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Hello,',\n",
       "  'score': 0.6458384990692139,\n",
       "  'token': 6,\n",
       "  'token_str': ','},\n",
       " {'sequence': 'Hello!',\n",
       "  'score': 0.12907041609287262,\n",
       "  'token': 328,\n",
       "  'token_str': '!'},\n",
       " {'sequence': 'Hello.',\n",
       "  'score': 0.025325661525130272,\n",
       "  'token': 4,\n",
       "  'token_str': '.'},\n",
       " {'sequence': 'Hello there',\n",
       "  'score': 0.02444182150065899,\n",
       "  'token': 89,\n",
       "  'token_str': ' there'},\n",
       " {'sequence': 'Hello World',\n",
       "  'score': 0.016941659152507782,\n",
       "  'token': 623,\n",
       "  'token_str': ' World'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm('Hello <mask>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commas dominate our written word and without proper punctuation the model is very tempted to just stuff in more of them. \n",
    "\n",
    "Varying things like punctuation, negatives, word order, etc. in my experience is important when you only have one token to play with as it can really bias a model torwards one way or another depending on the context of what you're trying to predict.  \n",
    "\n",
    "Okay, enough of explaining the basics now let's actually start doing some MLM-based EDA.  \n",
    "\n",
    "I already have some intuition of where to start, the PET paper uses a clever example with the AG's News dataset that exploits common web page text formatting that categorizes pages.  \n",
    "\n",
    "The AG News example looks something like this:\n",
    "\n",
    "\"[Category: _ _ _ ]\\nPAGE TITLE HERE \\nPAGE BODY HERE\"\n",
    "\n",
    "\n",
    "It's common enough for web pages to have that \"[Category _ _ _]\" tag formatting that MLMs trained on web text actually learn those patterns. \n",
    "\n",
    "So I'm hoping that I can come up with some similar ideas for our set. \n",
    "\n",
    "Let's remind ourselves of the categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what I think I'm going to do first is try to come up with patterns that generalize to all the categories to start. I was considering writing patterns for groupings of similar topics, then making specialist patterns to distinguish after the more general group has been identified, but we will see if that is necessary.\n",
    "\n",
    "The two patterns I want to start off with trying are these:\n",
    "1. \"Topic: _ _ _\\nDOC-HERE\"\n",
    "2. \"Tags: _ _ _\\nDOC-HERE\"\n",
    "\n",
    "\n",
    "For now, I'm not going to make any verbalizers, just come up with some general patterns and see what RoBERTa spits out for different classes and look for tokens that split the classes well.\n",
    "\n",
    "First let's get our data in a dataframe to help us organize this process a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text': newsgroups_train['data'], 'target_int': newsgroups_train['target']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['target_int'].apply(newsgroups_train['target_names'].__getitem__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This **definitely** isn't the most efficient way to score all of these, but I'm pretty hungry right now anyways so I'm going to not bother with optimizing all the Transformers-Pytorch-GPU nonsense and just let this run for a bit. It feels like every time I go to use Transformers Pipelines they have a new implementation for something anyways. Actually even while writing this notebook I noticed that they finally let you pass truncation kwargs when calling the pipeline, I used to have to do a hotfix to accomplish this.\n",
    "\n",
    "But anywho, just going to let this run. Will probably have to optimize this later as we will likely be doing a fair amount of iteration, but maybe we will get lucky and get to avoid this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4d8c64fcee4a68b59427574976bc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11314.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "topic_pattern = 'Topic: <mask>\\n{}'\n",
    "\n",
    "df['topic_pattern'] = df['text'].progress_apply(lambda doc: mlm(topic_pattern.format(doc), truncation=\"longest_first\", max_length=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b635095b148d4962b5d9eb7195d36d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11314.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tags_pattern = 'Tags: <mask>\\n{}'\n",
    "df['tags_pattern'] = df['text'].progress_apply(lambda doc: mlm(tags_pattern.format(doc), truncation=\"longest_first\", max_length=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished! So now we're just trying to find words that split the targets well.\n",
    "\n",
    "First going to flatten the tokens into a series of lists, then grab the unique tokens to see how many there are. If it's a small number sometimes you can get away just pruning them out yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic_patten_output_tokens'] = df['topic_pattern'].apply(lambda l: [d['token_str'].strip() for d in l])\n",
    "df['tags_patten_output_tokens'] = df['tags_pattern'].apply(lambda l: [d['token_str'].strip() for d in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_patten_output_tokens</th>\n",
       "      <th>tags_patten_output_tokens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Car, Cars, Vehicle, car, Auto]</td>\n",
       "      <td>[&lt;/s&gt;, Car, car, Cars, 1]</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Clock, Upgrade, Discussion, SI, Update]</td>\n",
       "      <td>[SI, clock, Clock, &lt;/s&gt;, upgrade]</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[PB, Hardware, FAQ, Feedback, Questions]</td>\n",
       "      <td>[&lt;/s&gt;, PB, FAQ, PR, Wikipedia]</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Abstract, News, Comments, Discussion, Communi...</td>\n",
       "      <td>[&lt;/s&gt;, news, comments, Comments, mail]</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NASA, Space, Discussion, Science, Discuss]</td>\n",
       "      <td>[&lt;/s&gt;, NASA, Shuttle, launch, shuttle]</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>[Discuss, , Discussion, ****, discussion]</td>\n",
       "      <td>[, Reply, &lt;/s&gt;, reply, 1]</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>[Help, Hardware, Technology, Discussion, Tech]</td>\n",
       "      <td>[&lt;/s&gt;, Mac, Apple, Software, screen]</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>[Discussion, Hardware, Miscellaneous, Feedback...</td>\n",
       "      <td>[&lt;/s&gt;, Hardware, mail, CPU, Linux]</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>[Sphere, sphere, Discuss, Discussion, Feedback]</td>\n",
       "      <td>[&lt;/s&gt;, Sphere, sphere, email, 1]</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>[theft, stolen, Lost, missing, Theft]</td>\n",
       "      <td>[stolen, &lt;/s&gt;, theft, missing, lost]</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              topic_patten_output_tokens  \\\n",
       "0                        [Car, Cars, Vehicle, car, Auto]   \n",
       "1               [Clock, Upgrade, Discussion, SI, Update]   \n",
       "2               [PB, Hardware, FAQ, Feedback, Questions]   \n",
       "3      [Abstract, News, Comments, Discussion, Communi...   \n",
       "4            [NASA, Space, Discussion, Science, Discuss]   \n",
       "...                                                  ...   \n",
       "11309          [Discuss, , Discussion, ****, discussion]   \n",
       "11310     [Help, Hardware, Technology, Discussion, Tech]   \n",
       "11311  [Discussion, Hardware, Miscellaneous, Feedback...   \n",
       "11312    [Sphere, sphere, Discuss, Discussion, Feedback]   \n",
       "11313              [theft, stolen, Lost, missing, Theft]   \n",
       "\n",
       "                    tags_patten_output_tokens                    target  \n",
       "0                   [</s>, Car, car, Cars, 1]                 rec.autos  \n",
       "1           [SI, clock, Clock, </s>, upgrade]     comp.sys.mac.hardware  \n",
       "2              [</s>, PB, FAQ, PR, Wikipedia]     comp.sys.mac.hardware  \n",
       "3      [</s>, news, comments, Comments, mail]             comp.graphics  \n",
       "4      [</s>, NASA, Shuttle, launch, shuttle]                 sci.space  \n",
       "...                                       ...                       ...  \n",
       "11309               [, Reply, </s>, reply, 1]                   sci.med  \n",
       "11310    [</s>, Mac, Apple, Software, screen]     comp.sys.mac.hardware  \n",
       "11311      [</s>, Hardware, mail, CPU, Linux]  comp.sys.ibm.pc.hardware  \n",
       "11312        [</s>, Sphere, sphere, email, 1]             comp.graphics  \n",
       "11313    [stolen, </s>, theft, missing, lost]           rec.motorcycles  \n",
       "\n",
       "[11314 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['topic_patten_output_tokens','tags_patten_output_tokens', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discussion       8418\n",
       "discuss          3725\n",
       "miscellaneous    3708\n",
       "feedback         2428\n",
       "news             2307\n",
       "                 ... \n",
       "arguments           1\n",
       "leafs               1\n",
       "rand                1\n",
       "vm                  1\n",
       "sexual              1\n",
       "Length: 1817, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([x.lower() for l in df['topic_patten_output_tokens'].tolist() for x in l]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so 1800 seems like a lot to do by hand, if it were somewhere between 100-300 I'd consider it but it's probably smarter to come up with an automagic way of doing this.\n",
    "\n",
    "Real quick, before we do that, let's get an idea of how big the tail is here, maybe we could get away with just lopping it off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discussion       8418\n",
       "discuss          3725\n",
       "miscellaneous    3708\n",
       "feedback         2428\n",
       "news             2307\n",
       "                 ... \n",
       "cr                 10\n",
       "schedule           10\n",
       "relationship       10\n",
       "revelations        10\n",
       "azerbaijan         10\n",
       "Length: 380, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([x.lower() for l in df['topic_patten_output_tokens'].tolist() for x in l]).value_counts()\n",
    "s[s >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit more reasonable! But I still don't feel like doing that manually, esp. with how many topics there are. Also considering why I'm doing this challenge I probably should accomplish this more analytically somehow xD. \n",
    "\n",
    "I'm trying to think of some metric that uses the frequency of the token in different topics to figure out which ones are the most niche to any given topic. My brain tells me that there already is a good metric out there for this, but in this case I think it's going to be pretty easy for us to come up with a ratio ourselves.\n",
    "\n",
    "I want tokens that commonly appear in one topic to be weighed higher, and I want tokens tokens that appear frequently appear in many topics to be pruned out. \n",
    "\n",
    "I have some ideas but let's first lay out the variables I'm thinking of potentially playing with here:\n",
    "\n",
    "Token = $k_n$ where $k_n \\in K$   \n",
    "Topic = $t_n$ where $t_n \\in T$  \n",
    "Set of Documents that are labeled with $k_n$ = $D_{k_n}$ where $D_{k_n} \\subset{D}$  \n",
    "Set of Documents that belong to topic $t_n$ = $D_{t_n}$ where $D_{t_n} \\subset{D}$  \n",
    "Token <-> Topic Frequency  = $\\mid D_{k_i}\\cap D_{t_j} \\mid$  \n",
    "Set of Unique Topics that token $k_n$ appears in = $T_{k_n}$  \n",
    "\n",
    "So intuitively, first thought is we can try something like:  \n",
    "$f(k_n) = \\frac{\\mid D_{k_n} \\mid}{\\mid T_{k_n} \\mid}$\n",
    "\n",
    "So here our metric is just frequency of the token divided by the number of unique topics that token appears in. \n",
    "\n",
    "But in that case large counts of common tokens could potentially still dwarf more niche tokens that appear less frequently. \n",
    "I really want a natural way of punishing tokens that appear in many topics. \n",
    "\n",
    "~But for science let's try it real quick.~ [**EDIT:** Scratch trying this, after some later exploration I'm going straight into the thing I actually want to do]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorry for all the wicked messy oneliners, but I'm going for quick and dirty\n",
    "\n",
    "# Token counts\n",
    "topic_pattern_token_counts = dict(pd.Series([x.lower() for l in df['topic_patten_output_tokens'].tolist() for x in l]).value_counts())\n",
    "tags_pattern_token_counts = dict(pd.Series([x.lower() for l in df['tags_patten_output_tokens'].tolist() for x in l]).value_counts())\n",
    "\n",
    "# Target counts\n",
    "target_counts = dict(df['target'].value_counts())\n",
    "\n",
    "# Token <-> Topic Frequencies\n",
    "topic_pattern_target_token_counts = dict(pd.Series([y for z in (df['target'].apply(lambda t: [t]) + df['topic_patten_output_tokens']).apply(lambda l: [(l[0], x.lower()) for x in l[1:]]).tolist() for y in z]).value_counts())\n",
    "tags_pattern_target_token_counts = dict(pd.Series([y for z in (df['target'].apply(lambda t: [t]) + df['tags_patten_output_tokens']).apply(lambda l: [(l[0], x.lower()) for x in l[1:]]).tolist() for y in z]).value_counts())\n",
    "\n",
    "# Unique topics by token\n",
    "topic_pattern_token2unique_targets = {s:[t[0] for t in topic_pattern_target_token_counts.keys() if s == t[1]] for s in topic_pattern_token_counts.keys()}\n",
    "tags_pattern_token2unique_targets = {s:[t[0] for t in tags_pattern_target_token_counts.keys() if s == t[1]] for s in tags_pattern_token_counts.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to plot out the # of unique targets per token real quick to see just how niche tokens are on average at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.Series(list(map(len, topic_pattern_token2unique_targets.values()))).hist(bins=np.arange(1, 20, 1))\n",
    "ax.set_xticks(np.arange(1, 20, 1))\n",
    "ax.set_title('# of unique topics per token')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance that doesn't look too bad I guess, but I think that it's currently being carried by the low frequency tail, let's validate that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.Series(list(map(len, [v for k,v in topic_pattern_token2unique_targets.items() if topic_pattern_token_counts[k]>=10]))).hist(bins=np.arange(1, 20, 1))\n",
    "ax.set_xticks(np.arange(1, 20, 1))\n",
    "ax.set_title('# of unique topics per token that has at least 10 occurences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah that's what I thought. Granted, these unique topics could still be rare occurences. Let's inspect one real quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.sport.hockey      509\n",
       "rec.sport.baseball      8\n",
       "rec.motorcycles         1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['topic_patten_output_tokens'].apply(lambda l: 'hockey' in [x.lower() for x in l])].target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so that actually looks pretty good, but it looks like RoBERTa labeled documents some topics under baseball and motorcycles with the \"hockey\" token, so going to look at a few of those. \n",
    "\n",
    "This next one's real topic is ``rec.sport.baseball``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa's output: ['Sports', 'Discussion', 'Hockey', 'Letters', 'Baseball']\n",
      "\n",
      "Document:\n",
      "From: cs902043@ariel.yorku.ca (SHAWN LUDDINGTON)\n",
      "Subject: Re: Jack Morris\n",
      "Organization: York University, Toronto, Canada\n",
      "Lines: 40\n",
      "\n",
      "In article <1993Apr18.032345.5178@cs.cornell.edu> tedward@cs.cornell.edu (Edward [Ted] Fischer) writes:\n",
      ">In article <1993Apr18.030412.1210@mnemosyne.cs.du.edu> gspira@nyx.cs.du.edu (Greg Spira) writes:\n",
      ">>Howard_Wong@mindlink.bc.ca (Howard Wong) writes:\n",
      ">>\n",
      ">>>Has Jack lost a bit of his edge? What is the worst start Jack Morris has had?\n",
      ">>\n",
      ">>Uh, Jack lost his edge about 5 years ago, and has had only one above\n",
      ">>average year in the last 5.\n",
      ">\n",
      ">Again goes to prove that it is better to be good than lucky.  You can\n",
      ">count on good tomorrow.  Lucky seems to be prone to bad starts (and a\n",
      ">bad finish last year :-).\n",
      ">\n",
      ">(Yes, I am enjoying every last run he gives up.  Who was it who said\n",
      ">Morris was a better signing than Viola?)\n",
      ">\n",
      ">Cheers,\n",
      ">-Valentine\n",
      "\n",
      "Hey Valentine, I don't see Boston with any world series rings on their\n",
      "fingers.  Damn, Morris now has three and probably the Hall of Fame in his \n",
      "future.  Therefore, I would have to say Toronto easily made the best \n",
      "signing.  And don't tell me Boston will win this year.  They won't \n",
      "even be in the top 4 in the division, more like 6th.\n",
      "\n",
      "Shawn\n"
     ]
    }
   ],
   "source": [
    "print(\"RoBERTa's output: {}\\n\".format(df[df['topic_patten_output_tokens'].apply(lambda l: 'hockey' in [x.lower() for x in l]) & df['target'].isin(['rec.motorcycles', 'rec.sport.baseball'])].iloc[0].topic_patten_output_tokens))\n",
    "print('Document:')\n",
    "print(df[df['topic_patten_output_tokens'].apply(lambda l: 'hockey' in [x.lower() for x in l]) & df['target'].isin(['rec.motorcycles', 'rec.sport.baseball'])].iloc[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseball was ranked below hockey there, but in fairness Boston and Toronto do both have pretty reputable hockey teams. Really the only thing here that makes this lean baseball over other sports is \"Jack Morris\" and \"World Series\". I wouldn't expect a model like RoBERTa to know that Jack Morris was a MLB player, maybe GPT3 could remember that but even then it's not guaranteed. Actually we can test whether RoBERTa knows real quick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'LeBron James is a special player.',\n",
       "  'score': 0.21372829377651215,\n",
       "  'token': 780,\n",
       "  'token_str': ' special'},\n",
       " {'sequence': 'LeBron James is a great player.',\n",
       "  'score': 0.15112999081611633,\n",
       "  'token': 372,\n",
       "  'token_str': ' great'},\n",
       " {'sequence': 'LeBron James is a franchise player.',\n",
       "  'score': 0.07300422340631485,\n",
       "  'token': 3468,\n",
       "  'token_str': ' franchise'},\n",
       " {'sequence': 'LeBron James is a basketball player.',\n",
       "  'score': 0.05553911253809929,\n",
       "  'token': 2613,\n",
       "  'token_str': ' basketball'},\n",
       " {'sequence': 'LeBron James is a team player.',\n",
       "  'score': 0.03637872636318207,\n",
       "  'token': 165,\n",
       "  'token_str': ' team'}]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm('LeBron James is a <mask> player.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it has an idea that LeBron is a basketball player, but that's not surprising, let's try Jack Morris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Jack Morris is a great player.',\n",
       "  'score': 0.0820646733045578,\n",
       "  'token': 372,\n",
       "  'token_str': ' great'},\n",
       " {'sequence': 'Jack Morris is a good player.',\n",
       "  'score': 0.07718237489461899,\n",
       "  'token': 205,\n",
       "  'token_str': ' good'},\n",
       " {'sequence': 'Jack Morris is a special player.',\n",
       "  'score': 0.051665615290403366,\n",
       "  'token': 780,\n",
       "  'token_str': ' special'},\n",
       " {'sequence': 'Jack Morris is a hockey player.',\n",
       "  'score': 0.02676667645573616,\n",
       "  'token': 5006,\n",
       "  'token_str': ' hockey'},\n",
       " {'sequence': 'Jack Morris is a football player.',\n",
       "  'score': 0.02573949471116066,\n",
       "  'token': 1037,\n",
       "  'token_str': ' football'}]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm('Jack Morris is a <mask> player.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... interesting, I wonder if there's a Jack Morris that's in the NHL. \n",
    "\n",
    "(Googled around a bit): There is a very young Jack Morris in the NHL, but I don't think RoBERTa would have seen that as that was really recent and I'm pretty sure RoBERTa was trained sometime in 2018/2019. What's more likely is that there are several other more famous NHL players with the last name NHL that seem to be a lot more well known than Jack Morris, and were playing more in the internet era, so RoBERTa, if it know's anything, is likely associating the name \"Morris\" with the NHL. There are a decent number of NFL players with the name Morris although Derek Morris (NHL) seems to be a bit more well known than them. \n",
    "\n",
    "Actually the probabilities here are pretty close to equal... so it's also just very possible that I'm reading too deep into this and this was just some coincendental or even racially biased sorting.\n",
    "\n",
    "Then again, RoBERTa _does_ know things though, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'LeBron James plays for himself',\n",
       "  'score': 0.25127264857292175,\n",
       "  'token': 1003,\n",
       "  'token_str': ' himself'},\n",
       " {'sequence': 'LeBron James plays for charity',\n",
       "  'score': 0.04965246841311455,\n",
       "  'token': 4440,\n",
       "  'token_str': ' charity'},\n",
       " {'sequence': 'LeBron James plays for Cleveland',\n",
       "  'score': 0.02661042846739292,\n",
       "  'token': 2986,\n",
       "  'token_str': ' Cleveland'},\n",
       " {'sequence': 'LeBron James plays for money',\n",
       "  'score': 0.023090366274118423,\n",
       "  'token': 418,\n",
       "  'token_str': ' money'},\n",
       " {'sequence': 'LeBron James plays for LeBron',\n",
       "  'score': 0.021882962435483932,\n",
       "  'token': 9517,\n",
       "  'token_str': ' LeBron'}]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm('LeBron James plays for <mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Jack Morris plays for Eagles',\n",
       "  'score': 0.017865249887108803,\n",
       "  'token': 3846,\n",
       "  'token_str': ' Eagles'},\n",
       " {'sequence': 'Jack Morris plays for Kings',\n",
       "  'score': 0.01767733320593834,\n",
       "  'token': 5414,\n",
       "  'token_str': ' Kings'},\n",
       " {'sequence': 'Jack Morris plays for Giants',\n",
       "  'score': 0.012834325432777405,\n",
       "  'token': 4608,\n",
       "  'token_str': ' Giants'},\n",
       " {'sequence': 'Jack Morris plays for Panthers',\n",
       "  'score': 0.011746032163500786,\n",
       "  'token': 6495,\n",
       "  'token_str': ' Panthers'},\n",
       " {'sequence': 'Jack Morris plays for Minnesota',\n",
       "  'score': 0.010720044374465942,\n",
       "  'token': 3161,\n",
       "  'token_str': ' Minnesota'}]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm('Jack Morris plays for <mask>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, so Jack Morris <> Minnesota is the player they were talking about in that document, the rest are Morris's with different first names... so maybe I wasn't reading too much into it.\n",
    "\n",
    "Okay enough messing about, let's move on and look at the motorcycle example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa's output: ['Discussion', 'Weather', 'Cold', 'Cycling', 'Hockey']\n",
      "\n",
      "Document:\n",
      "From: azw@aber.ac.uk (Andy Woodward)\n",
      "Subject: Re: Its still cold, but...\n",
      "Organization: University College of Wales, Aberystwyth\n",
      "Lines: 13\n",
      "Nntp-Posting-Host: 144.124.112.30\n",
      "\n",
      "\n",
      ">> \n",
      ">> One thing is certain, though, its still too cold.  After about 40\n",
      ">> minutes, I had to stop and hold my muffler for a while.  \n",
      "\n",
      "Be VERY careful about this. If youre really cold the muffler will\n",
      "feel fine till you leave all the charred skin on it when you peel\n",
      "your hands off - I speak from experience. You can also do all \n",
      "kindsa (Americanism of the day) damage to your circulation warming \n",
      "hands up on something too hot. By far the best (fastest and safest)\n",
      "way to do it is to shove the hands up the opposit sleeves and\n",
      "stand there like a Ming emporer for a while. Five minutes should \n",
      "do it.\n"
     ]
    }
   ],
   "source": [
    "print(\"RoBERTa's output: {}\\n\".format(df[df['topic_patten_output_tokens'].apply(lambda l: 'hockey' in [x.lower() for x in l]) & df['target'].isin(['rec.motorcycles', 'rec.sport.baseball'])].iloc[2].topic_patten_output_tokens))\n",
    "print('Document:')\n",
    "print(df[df['topic_patten_output_tokens'].apply(lambda l: 'hockey' in [x.lower() for x in l]) & df['target'].isin(['rec.motorcycles', 'rec.sport.baseball'])].iloc[2].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hockey was last there, and it did pick up on \"Cycling\" so I don't think there's any real problem here, probably some random noise from them talking about being cold and such.\n",
    "\n",
    "Okay this notebook is getting really long so let's get back to the metric, here's what I actually want try:  \n",
    "$f(k_n) =  \\mid D_{k_n}\\mid \\cdot \\sum_{j=0}^{m}{r_j^m}$  \n",
    "\n",
    "$m = {\\mid T_{k_n} \\mid}$  \n",
    "\n",
    "$r_j = \\frac{\\mid D_{k_n}\\cap D_{t_j} \\mid}{\\mid D_{k_n} \\mid}$ = Token <-> Topic membership \n",
    "\n",
    "So the idea here is that we calculate our metric for token $k_n$ by summing up all the the token <-> topic memberships $r_j$ and raising each membership value to the power of the number of unique topics that the token appears in.  \n",
    "\n",
    "Intuition being that we want to reward large memberships in a single topic, while punishing membership to many topics. Then we weight this by token frequency. This should kill tokens with membership amongst many topics. \n",
    "\n",
    "If a token has membership mostly in in one topic but still occasionally appears in other topics, it still has a chance at not vanishing, for example $.98^{20}=.667$ whereas $.05^{20} \\approx 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pattern_mlm_metric = {}\n",
    "for token, topics in topic_pattern_token2unique_targets.items():\n",
    "    topic_pattern_mlm_metric[token] = topic_pattern_token_counts[token] * sum([pow(topic_pattern_target_token_counts[(t, token)] / topic_pattern_token_counts[token], len(topics)) for t in topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_pattern_mlm_metric = {}\n",
    "for token, topics in tags_pattern_token2unique_targets.items():\n",
    "    tags_pattern_mlm_metric[token] = tags_pattern_token_counts[token] * sum([pow(tags_pattern_target_token_counts[(t, token)] / tags_pattern_token_counts[token], len(topics)) for t in topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort it\n",
    "topic_pattern_mlm_metric = dict(sorted([(k,v) for k,v in topic_pattern_mlm_metric.items()], key=lambda k: k[1], reverse=True))\n",
    "tags_pattern_mlm_metric = dict(sorted([(k,v) for k,v in tags_pattern_mlm_metric.items()], key=lambda k: k[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hockey': 668.3491931059468,\n",
       " 'baseball': 464.7702224602278,\n",
       " 'space': 252.06976744186045,\n",
       " 'guns': 224.387472455939,\n",
       " 'privacy': 223.98328178891484,\n",
       " 'palestine': 163.07079584048182,\n",
       " 'nasa': 151.91404023451966,\n",
       " 'auto': 149.09439507440166,\n",
       " 'warning': 133.08602039231923,\n",
       " 'encryption': 128.06060606060606,\n",
       " 'firearms': 127.0,\n",
       " 'nsa': 122.20505798030415,\n",
       " 'health': 114.38428754366856,\n",
       " 'israel': 109.01801801801803,\n",
       " 'nhl': 86.0,\n",
       " 'vehicle': 82.60858721697883,\n",
       " 'x': 71.95261065992028,\n",
       " 'cars': 69.30202404207363,\n",
       " 'medical': 68.02857142857144,\n",
       " 'athletics': 63.2608695652174,\n",
       " 'christianity': 60.5606810771646,\n",
       " 'armenia': 57.0,\n",
       " 'crypto': 56.0,\n",
       " 'church': 55.62390670553936,\n",
       " 'car': 54.66255144032922,\n",
       " 'zionism': 48.03999999999999,\n",
       " 'syria': 41.0,\n",
       " 'hezbollah': 41.0,\n",
       " 'hell': 41.0,\n",
       " 'cycling': 40.047619047619044}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(topic_pattern_mlm_metric.items())[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hockey': 677.0393203512141,\n",
       " 'baseball': 506.31426867929935,\n",
       " 'guns': 272.7137882530453,\n",
       " 'privacy': 177.21990048099303,\n",
       " 'nhl': 161.01226993865032,\n",
       " 'israel': 152.1670074457004,\n",
       " 'encryption': 142.05479452054794,\n",
       " 'warning': 137.0,\n",
       " 'nsa': 132.8359966156178,\n",
       " 'space': 120.0,\n",
       " 'palestine': 103.0747663551402,\n",
       " 'cryptography': 100.1126735493058,\n",
       " 'auto': 99.63806298745584,\n",
       " 'armenia': 85.0,\n",
       " 'firearms': 82.09302325581395,\n",
       " 'security': 78.37033563637706,\n",
       " 'gun': 73.0,\n",
       " 'sale': 69.41779749355294,\n",
       " 'christianity': 56.56285714285714,\n",
       " 'cars': 55.267765731319265,\n",
       " 'motorcycle': 52.03703703703704,\n",
       " 'zionism': 52.0,\n",
       " 'car': 51.75651900729696,\n",
       " 'armenian': 47.0,\n",
       " 'x': 44.40627078381888,\n",
       " 'warnings': 43.0,\n",
       " 'hezbollah': 42.04545454545455,\n",
       " 'phillies': 42.04545454545455,\n",
       " 'church': 41.80220105268796,\n",
       " 'sports': 40.64950093663013}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(tags_pattern_mlm_metric.items())[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few weird ones in there, but I checked them out and for the most part it looks good to me. \n",
    "\n",
    "So great! We accomplished what we wanted to, now we just need to make a cutoff.  \n",
    "\n",
    "For now, let's just use the first 200 tokens and see what shakes out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitelisted token count frequency\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    10259\n",
       "1      908\n",
       "2      127\n",
       "3       19\n",
       "4        1\n",
       "Name: topic_patten_output_tokens, dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_pattern_whitelist = list(topic_pattern_mlm_metric.keys())[:200]\n",
    "print('Whitelisted token count frequency')\n",
    "df['topic_patten_output_tokens'].apply(lambda l: [s for s in l if s in topic_pattern_whitelist]).apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitelisted token count frequency\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    8931\n",
       "1    1763\n",
       "2     501\n",
       "3     101\n",
       "4      16\n",
       "5       2\n",
       "Name: tags_patten_output_tokens, dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_pattern_whitelist = list(tags_pattern_mlm_metric.keys())[:200]\n",
    "print('Whitelisted token count frequency')\n",
    "df['tags_patten_output_tokens'].apply(lambda l: [s for s in l if s in tags_pattern_whitelist]).apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our current whitelist leaves ~10k documents without tokens. This is potentially okay as we will eventually force the MLM to pick the best of the whitelisted tokens. \n",
    "\n",
    "Also interestingly it seems that the tags pattern is faring quite a bit better from this perspective. But let's see if we even have enough examples for every topic, I have a feeling we may need to move the threshold down a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_topic_pattern_whitelist_pairs = [x for l in (df['target'].apply(lambda t: [t]) + df['topic_patten_output_tokens'].apply(lambda l: [s for s in l if s in topic_pattern_whitelist])).apply(lambda l: [(l[0],x) for x in l[1:]]).tolist() for x in l if x]\n",
    "target_topic_pattern_whitelist_token_vc = {target:[] for target in dict(target_topic_pattern_whitelist_pairs).keys()}\n",
    "for target, token in target_topic_pattern_whitelist_pairs:\n",
    "    target_topic_pattern_whitelist_token_vc[target].append(token)\n",
    "\n",
    "for target in target_topic_pattern_whitelist_token_vc.keys():\n",
    "    target_topic_pattern_whitelist_token_vc[target] = dict(pd.Series(target_topic_pattern_whitelist_token_vc[target]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tags_pattern_whitelist_pairs = [x for l in (df['target'].apply(lambda t: [t]) + df['tags_patten_output_tokens'].apply(lambda l: [s for s in l if s in tags_pattern_whitelist])).apply(lambda l: [(l[0],x) for x in l[1:]]).tolist() for x in l if x]\n",
    "target_tags_pattern_whitelist_token_vc = {target:[] for target in dict(target_tags_pattern_whitelist_pairs).keys()}\n",
    "for target, token in target_tags_pattern_whitelist_pairs:\n",
    "    target_tags_pattern_whitelist_token_vc[target].append(token)\n",
    "\n",
    "for target in target_tags_pattern_whitelist_token_vc.keys():\n",
    "    target_tags_pattern_whitelist_token_vc[target] = dict(pd.Series(target_tags_pattern_whitelist_token_vc[target]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rec.autos': {'warning': 45,\n",
       "  'auto': 29,\n",
       "  'car': 13,\n",
       "  'warnings': 13,\n",
       "  'automotive': 11,\n",
       "  'cars': 7,\n",
       "  'oil': 7,\n",
       "  'radar': 4,\n",
       "  'hail': 3,\n",
       "  'sales': 1,\n",
       "  'maintenance': 1,\n",
       "  'cr': 1},\n",
       " 'rec.sport.hockey': {'hockey': 177,\n",
       "  'chemistry': 17,\n",
       "  'golf': 4,\n",
       "  'notes': 3,\n",
       "  'baseball': 2,\n",
       "  'playoffs': 2,\n",
       "  'basketball': 1},\n",
       " 'sci.crypt': {'encryption': 130,\n",
       "  'security': 69,\n",
       "  'privacy': 39,\n",
       "  'cryptography': 20,\n",
       "  'crypto': 3,\n",
       "  'chaos': 3,\n",
       "  'password': 1,\n",
       "  'guns': 1},\n",
       " 'talk.politics.guns': {'guns': 83,\n",
       "  'gun': 23,\n",
       "  'firearms': 11,\n",
       "  'militia': 3,\n",
       "  'privacy': 2,\n",
       "  'encryption': 2},\n",
       " 'talk.politics.mideast': {'genocide': 24, 'correspondence': 8, 'was': 3},\n",
       " 'sci.space': {'space': 9, 'rocket': 5, 'mining': 3, 'moon': 1, 'comet': 1},\n",
       " 'sci.electronics': {'radar': 6,\n",
       "  'electricity': 2,\n",
       "  'privacy': 1,\n",
       "  'sale': 1,\n",
       "  'electrical': 1},\n",
       " 'comp.graphics': {'graphics': 12,\n",
       "  '42': 11,\n",
       "  'sphere': 8,\n",
       "  'drawing': 5,\n",
       "  'neuroscience': 1,\n",
       "  'color': 1},\n",
       " 'rec.sport.baseball': {'baseball': 102, 'notes': 14},\n",
       " 'sci.med': {'health': 16,\n",
       "  'medical': 3,\n",
       "  'smoking': 3,\n",
       "  'cancer': 3,\n",
       "  'nutrition': 2,\n",
       "  'pain': 2,\n",
       "  'diabetes': 2,\n",
       "  'chemistry': 2,\n",
       "  'diet': 1,\n",
       "  'neuroscience': 1,\n",
       "  'sale': 1},\n",
       " 'misc.forsale': {'sale': 8,\n",
       "  'car': 5,\n",
       "  'camera': 3,\n",
       "  'oil': 2,\n",
       "  'cars': 2,\n",
       "  'auto': 1,\n",
       "  'notes': 1,\n",
       "  'correspondence': 1,\n",
       "  'motorcycle': 1,\n",
       "  'baseball': 1,\n",
       "  'marketing': 1,\n",
       "  'auction': 1,\n",
       "  'chemistry': 1},\n",
       " 'comp.windows.x': {'x': 16,\n",
       "  'animation': 7,\n",
       "  'drawing': 2,\n",
       "  'window': 2,\n",
       "  'open': 2,\n",
       "  'windows': 2,\n",
       "  'security': 1,\n",
       "  'color': 1},\n",
       " 'comp.os.ms-windows.misc': {'window': 3,\n",
       "  'windows': 3,\n",
       "  'sales': 1,\n",
       "  'security': 1,\n",
       "  'sale': 1,\n",
       "  'baseball': 1},\n",
       " 'alt.atheism': {'atheism': 11,\n",
       "  'religion': 8,\n",
       "  'http': 7,\n",
       "  'from': 5,\n",
       "  'genocide': 4,\n",
       "  'thoughts': 4,\n",
       "  'car': 1},\n",
       " 'comp.sys.ibm.pc.hardware': {'gateway': 3, 'date': 2, 'graphics': 1},\n",
       " 'soc.religion.christian': {'religion': 12,\n",
       "  'marriage': 6,\n",
       "  'anger': 4,\n",
       "  'prayer': 4,\n",
       "  'atheism': 3,\n",
       "  'family': 2,\n",
       "  'genocide': 2,\n",
       "  'church': 1,\n",
       "  'heaven': 1},\n",
       " 'comp.sys.mac.hardware': {'cache': 2, 'sales': 1, 'marketing': 1, 'ram': 1},\n",
       " 'rec.motorcycles': {'helmet': 13,\n",
       "  'motorcycle': 13,\n",
       "  'helmets': 13,\n",
       "  'dogs': 6,\n",
       "  'bike': 3,\n",
       "  'story': 2,\n",
       "  'security': 2,\n",
       "  'cycling': 1,\n",
       "  'riding': 1,\n",
       "  'shipping': 1},\n",
       " 'talk.politics.misc': {'justice': 4,\n",
       "  'rail': 4,\n",
       "  'rape': 3,\n",
       "  'marijuana': 2,\n",
       "  'taxes': 2,\n",
       "  'tax': 2,\n",
       "  'privacy': 1},\n",
       " 'talk.religion.misc': {'religion': 7}}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_topic_pattern_whitelist_token_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_tags_pattern_whitelist_token_vc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so it seems for certain topics we have tokens that do a really good job of defining the topic. Then there are others with topics that have more overlap, for example, all the religious topics have the token \"religion\". I think it would require more patterns/feature engineering to do this without finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
